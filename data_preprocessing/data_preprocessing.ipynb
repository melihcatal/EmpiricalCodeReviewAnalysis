{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lizard \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/gh_apache_!_accumulo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_function_annotation(file_content, start_line, end_line):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_function(file_content, start_line, end_line):\n",
    "    \"\"\"\n",
    "    extract the function body from the file content\n",
    "    \"\"\"\n",
    "    lines = file_content.splitlines()\n",
    "    # -1 to exclude the last line }\n",
    "    function_body = lines[start_line-1:end_line]\n",
    "    # concat the lines\n",
    "    function_body = \" \".join(function_body)\n",
    "    return function_body\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_functions(file_content_type):\n",
    "    extracted_functions = []\n",
    "    # loop through the rows. data is the dataframe that defined above\n",
    "    for index, row in data.iterrows():\n",
    "        file_content = row[file_content_type]\n",
    "        # provide the file content to lizard to extract the functions, the function needs a filename to work so we just use the filename\n",
    "        parse_result = lizard.analyze_file.analyze_source_code(row['filename'], file_content)\n",
    "        functions = parse_result.function_list\n",
    "        for function in functions:\n",
    "            print(function.__dict__)\n",
    "            # from the file content, extract the function body using the start and end line\n",
    "            method = extract_function(file_content, function.start_line, function.end_line)\n",
    "            function_data = {\n",
    "                \"file_name\": row['filename'],\n",
    "                \"dicussion\": row['discussion'],\n",
    "                \"method_name\": function.long_name,\n",
    "                \"method\": method,\n",
    "                \"start_line\": function.start_line,\n",
    "                \"end_line\": function.end_line,\n",
    "            }\n",
    "            extracted_functions.append(function_data)\n",
    "            \n",
    "        # break to only loop the first row. TODO remove this \n",
    "        break\n",
    "    return extracted_functions\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_functions_while = parse_functions('file_content_while')\n",
    "extracted_functions_after = parse_functions('file_content_after')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linking Reviewer Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same file should'nt have the same method name more than once. Remove the duplicates of the same method name in the same file\n",
    "def get_unique_methods(extracted_functions):\n",
    "    extracted_functions = pd.DataFrame(extracted_functions)\n",
    "    extracted_functions = extracted_functions.drop_duplicates(subset=['method_name', 'file_name'])\n",
    "    extracted_functions = extracted_functions.reset_index(drop=True)\n",
    "    return extracted_functions.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_extracted_functions_while = get_unique_methods(extracted_functions_while)\n",
    "unique_extracted_functions_after = get_unique_methods(extracted_functions_after)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the methods that we are in the file that we are interested in\n",
    "def filter_methods(filename):\n",
    "    #return [method for method in extracted_functions_while if method['file_name'] == filename]\n",
    "    return [method for method in unique_extracted_functions_while if method['file_name'] == filename]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_comment_in_line( commnet_start_line, comment_end_line, function_start_line, function_end_line):\n",
    "    if function_start_line >= commnet_start_line and function_end_line <= comment_end_line:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data that has the comment info \n",
    "def filter_raw_dataframe(data):\n",
    "    # get start line not NaN\n",
    "    df = data[data['start_line'].notna()]\n",
    "    # get the rows that owner_id and user_id is not same \n",
    "    df = df[df['owner_id'] != df['user_id']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = filter_raw_dataframe(data)\n",
    "\n",
    "# loop through df dataframe \n",
    "for index, row in df.iterrows():\n",
    "    comment_start_line = row['start_line']\n",
    "    comment_end_line = row['line']\n",
    "    filename = row['filename']\n",
    "    filtered_methods = filter_methods(filename)\n",
    "    #print( str(len(filtered_methods)) + \" \" + filename)\n",
    "    #print(row['url'] + \" \" + row['message'] +  row['filename'] )\n",
    "    #print(\"*****************\")\n",
    "    for method in filtered_methods:\n",
    "        #print (method['method_name'] + \" \" + str(method['start_line']) + \" \" + str(method['end_line']))\n",
    "        if check_comment_in_line(comment_start_line, comment_end_line, method['start_line'], method['end_line']):\n",
    "            #pass\n",
    "            #print(\"found \")\n",
    "            print(method['method_name']  + \" \" +  str(method['start_line']) + \" \" +str( method['end_line']) + \" \" + row['url'] + \" \" + row['message'] + \" \" +  row['filename'] + \" \" + str(comment_start_line) + \" \" + str(comment_end_line) )\n",
    "            #print(\"found \" + str(comment_start_line)  )\n",
    "    #break            \n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell is not related to the project. Just to test the code\n",
    "def get_method_by_file_name(file_name):\n",
    "    return [method for method in unique_extracted_functions_while if method['file_name'] == file_name]\n",
    "\n",
    "target_file_name = \"core/src/main/java/org/apache/accumulo/core/client/admin/PluginConfig.java\"\n",
    "target_file_methods = get_method_by_file_name(target_file_name)\n",
    "target_file_methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
