{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the results of the 2-encoders and 1-encoder models\n",
    "\n",
    "** This notebook compares the results of the 2-encoders and 1-encoder models.**\n",
    "\n",
    "The 2-encoders model is trained with the review comment *rnl*  and the function that the comment is associated with *ms*. \n",
    "The 1-encoder model is trained with the function on review *ms* only. \n",
    "\n",
    "**Results** \n",
    "- The 2-encoders model performs better than the 1-encoder model.\n",
    "- Overall results are not as good as the results in the paper. \n",
    "    -  In the paper 1-encoder model with the beam size of 1 achieves 2.91% perfect prediction rate. In our experiment, the 1-encoder model with the beam size of 1 achieves 1.5% perfect prediction rate.  \n",
    "    - In the paper 2-encoders model with the beam size of 1 achieves 12.16% perfect prediction rate. In our experiment, the 2-encoders model with the beam size of 1 achieves 4.7% perfect prediction rate.\n",
    "- This difference may be due to the difference in the dataset. The paper uses the dataset from both the Gerrit and the GitHub which creates a total of 17194 training data. However, our experiment uses the dataset from the GitHub only which creates a total of 8315 training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_encoders_predictions_path = \"./code/2-encoders/predictions.txt\"\n",
    "one_encoder_predictions_path = \"./code/1-encoder/predictions.txt\"\n",
    "\n",
    "two_encoders_target_path = \"./datasets/2-encoders/test/tgt-test.txt\"\n",
    "two_encoers_ms_path = \"./datasets/2-encoders/test/src1-test.txt\"\n",
    "two_encoders_rnl_path = \"./datasets/2-encoders/test/src2-test.txt\"\n",
    "\n",
    "one_encoder_target_path = \"./datasets/1-encoder/test/tgt-test.txt\"\n",
    "one_encoder_ms_path = \"./datasets/1-encoder/test/src-test.txt\"\n",
    "\n",
    "two_encoders_predictions = open(two_encoders_predictions_path, \"r\").readlines()\n",
    "one_encoder_predictions = open(one_encoder_predictions_path, \"r\").readlines()\n",
    "\n",
    "two_encoders_target = open(two_encoders_target_path, \"r\").readlines()\n",
    "two_encoders_ms = open(two_encoers_ms_path, \"r\").readlines()\n",
    "two_encoders_rnl = open(two_encoders_rnl_path, \"r\").readlines()\n",
    "\n",
    "one_encoder_target = open(one_encoder_target_path, \"r\").readlines()\n",
    "one_encoder_ms = open(one_encoder_ms_path, \"r\").readlines()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 encoders accuracy percentage:  4.693140794223827 %\n",
      "1 encoder accuracy percentage:  1.5643802647412757 %\n"
     ]
    }
   ],
   "source": [
    "def correct_predictions_percentage(predictions, targets):\n",
    "    assert len(predictions) == len(targets)\n",
    "    correct = 0\n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] == targets[i]:\n",
    "            correct += 1\n",
    "    return correct / len(predictions) * 100\n",
    "\n",
    "print(\"2 encoders accuracy percentage: \", correct_predictions_percentage(two_encoders_predictions, two_encoders_target), \"%\")\n",
    "print(\"1 encoder accuracy percentage: \", correct_predictions_percentage(one_encoder_predictions, one_encoder_target), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 encoders correct predictions:  [90, 95, 134, 136, 140, 191, 238, 263, 278, 287, 296, 337, 351, 367, 380, 382, 398, 420, 435, 456, 484, 492, 525, 574, 606, 613, 649, 657, 675, 705, 713, 720, 729, 781, 791, 796, 797, 800, 821]\n",
      "1 encoder correct predictions:  [91, 135, 145, 215, 359, 421, 553, 614, 618, 632, 715, 802, 823]\n"
     ]
    }
   ],
   "source": [
    "def get_correct_predictions(predictions, targets):\n",
    "    assert len(predictions) == len(targets)\n",
    "    correct = []\n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] == targets[i]:\n",
    "            correct.append(i)\n",
    "    return correct\n",
    "\n",
    "two_encoders_correct_predictions = get_correct_predictions(two_encoders_predictions, two_encoders_target)\n",
    "one_encoder_correct_predictions = get_correct_predictions(one_encoder_predictions, one_encoder_target)\n",
    "\n",
    "print(\"2 encoders correct predictions: \", two_encoders_correct_predictions)\n",
    "print(\"1 encoder correct predictions: \", one_encoder_correct_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_two_encoders(index):\n",
    "    print(\"MS: \", two_encoders_ms[index])\n",
    "    print(\"RNL: \", two_encoders_rnl[index])\n",
    "    print(\"Prediction: \", two_encoders_predictions[index])\n",
    "    print(\"Target: \", two_encoders_target[index])\n",
    "\n",
    "\n",
    "def get_sample_one_encoder(index):\n",
    "    print(\"MS: \", one_encoder_ms[index])\n",
    "    print(\"Prediction: \", one_encoder_predictions[index])\n",
    "    print(\"Target: \", one_encoder_target[index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 2 encoder: \n",
      "MS:  public void VAR_1 ( VAR_2 VAR_1 ) { this . VAR_1 = VAR_1 ; } }\n",
      "\n",
      "RNL:  Could use final VAR_2 VAR_1 please\n",
      "\n",
      "Prediction:  public void VAR_1 ( final VAR_2 VAR_1 ) { this . VAR_1 = VAR_1 ; } }\n",
      "\n",
      "Target:  public void VAR_1 ( final VAR_2 VAR_1 ) { this . VAR_1 = VAR_1 ; } }\n",
      "\n",
      "**************************************************\n",
      "Sample 1 encoder: \n",
      "MS:  protected synchronized void METHOD_1 ( ) { }\n",
      "\n",
      "Prediction:  protected void METHOD_1 ( ) { }\n",
      "\n",
      "Target:  protected void METHOD_1 ( ) { }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample 2 encoder: \")\n",
    "get_sample_two_encoders(two_encoders_correct_predictions[0])\n",
    "print(\"*\" * 50)\n",
    "print(\"Sample 1 encoder: \")\n",
    "get_sample_one_encoder(one_encoder_correct_predictions[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Graphs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-encoder model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=\"545\" alt=\"image\" src=\"https://user-images.githubusercontent.com/46859098/236644947-06124430-fd71-42f5-a590-013978daf9dc.png\">\n",
    "\n",
    "<img width=\"535\" alt=\"image\" src=\"https://user-images.githubusercontent.com/46859098/236645065-2a1b1cfc-52fc-4381-9591-80d8f45d1a68.png\">\n",
    "\n",
    "<img width=\"549\" alt=\"image\" src=\"https://user-images.githubusercontent.com/46859098/236645089-2ba583a8-6aa7-46cd-8cd6-a11a05ee9f7b.png\">\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-encoders model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=\"547\" alt=\"image\" src=\"https://user-images.githubusercontent.com/46859098/236645239-136b89a0-9812-4c55-a024-28537f7e69b5.png\">\n",
    "<img width=\"542\" alt=\"image\" src=\"https://user-images.githubusercontent.com/46859098/236645258-b9672f9b-fdc0-43e7-af5b-ea75d3a6782d.png\">\n",
    "<img width=\"537\" alt=\"image\" src=\"https://user-images.githubusercontent.com/46859098/236645268-f216ce2d-ccd9-481b-9929-fd64059dfbbf.png\">\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
