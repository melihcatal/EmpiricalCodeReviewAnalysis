{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the results of the 2-encoders and 1-encoder models\n",
    "\n",
    "** This notebook compares the results of the 2-encoders and 1-encoder models.**\n",
    "\n",
    "The 2-encoders model is trained with the review comment *rnl*  and the function that the comment is associated with *ms*. \n",
    "The 1-encoder model is trained with the function on review *ms* only. \n",
    "\n",
    "**Results** \n",
    "- The 2-encoders model performs better than the 1-encoder model.\n",
    "- Overall results are not as good as the results in the paper. \n",
    "    - In the paper 1-encoder model with the beam size of 1 achieves 2.91% perfect prediction rate. In our experiment, the 1-encoder model with the beam size of 1 achieves 1.5% perfect prediction rate.\n",
    "    - In the paper 1-encoder model with the beam size of 10 achieves 15.76% perfect prediction rate. In our experiment, the 1-encoder model with the beam size of 10 achieves 10.34% perfect prediction rate.\n",
    "    - In the paper 2-encoders model with the beam size of 1 achieves 12.16% perfect prediction rate. In our experiment, the 2-encoders model with the beam size of 1 achieves 4.7% perfect prediction rate.\n",
    "    - In the paper 2-encoders model with the beam size of 10 achieves 30.72% perfect prediction rate. In our experiment, the 2-encoders model with the beam size of 10 achieves 20.93% perfect prediction rate.\n",
    "\n",
    "- This difference may be due to the difference in the dataset. The paper uses the dataset from both the Gerrit and the GitHub which creates a total of 17194 training data. However, our experiment uses the dataset from the GitHub only which creates a total of 8315 training data. Also the paper uses 2566 different GitHub projects while our experiment uses 1986 different GitHub projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_encoders_one_beam_predictions_path = \"./code/2-encoders/predictions.txt\"\n",
    "two_encoders_ten_beam_predictions_path = \"./code/2-encoders/10_beam_predictions.txt\"\n",
    "\n",
    "one_encoder_one_beam_predictions_path = \"./code/1-encoder/predictions.txt\"\n",
    "one_encoder_ten_beam_predictions_path = \"./code/1-encoder/10_beam_predictions.txt\"\n",
    "\n",
    "\n",
    "two_encoders_target_path = \"./datasets/2-encoders/test/tgt-test.txt\"\n",
    "two_encoers_ms_path = \"./datasets/2-encoders/test/src1-test.txt\"\n",
    "two_encoders_rnl_path = \"./datasets/2-encoders/test/src2-test.txt\"\n",
    "\n",
    "one_encoder_target_path = \"./datasets/1-encoder/test/tgt-test.txt\"\n",
    "one_encoder_ms_path = \"./datasets/1-encoder/test/src-test.txt\"\n",
    "\n",
    "dataset_with_mapping_path = \"./datasets/ms_mr_rnl_map_dataset.csv\"\n",
    "\n",
    "two_encoders_one_beam_predictions = open(two_encoders_one_beam_predictions_path, \"r\").readlines()\n",
    "two_encoders_ten_beam_predictions = open(two_encoders_ten_beam_predictions_path, \"r\").readlines()\n",
    "\n",
    "one_encoder_one_beam_predictions = open(one_encoder_one_beam_predictions_path, \"r\").readlines()\n",
    "one_encoder_ten_beam_predictions = open(one_encoder_ten_beam_predictions_path, \"r\").readlines()\n",
    "\n",
    "two_encoders_target = open(two_encoders_target_path, \"r\").readlines()\n",
    "two_encoders_ms = open(two_encoers_ms_path, \"r\").readlines()\n",
    "two_encoders_rnl = open(two_encoders_rnl_path, \"r\").readlines()\n",
    "\n",
    "one_encoder_target = open(one_encoder_target_path, \"r\").readlines()\n",
    "one_encoder_ms = open(one_encoder_ms_path, \"r\").readlines()\n",
    "\n",
    "dataset_with_mapping = pd.read_csv(dataset_with_mapping_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_data = \"../data/ms_mr_rnl_map_dataset.csv\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perfect Prediction Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_predictions_percentage_10_beam(predictions, targets):\n",
    "    # for the 10 predictions check if any of them is correct\n",
    "    current_target_index = 0\n",
    "    correct_predictions = 0\n",
    "    for i in range(0, len(predictions), 10):\n",
    "        for j in range(10):\n",
    "            if predictions[i + j].strip() == targets[current_target_index].strip():\n",
    "                correct_predictions += 1\n",
    "                break\n",
    "        current_target_index += 1\n",
    "        \n",
    "    return correct_predictions / len(targets) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correct_predictions_10_beam(predictions, targets):\n",
    "    # for the 10 predictions check if any of them is correct\n",
    "    current_target_index = 0\n",
    "    correct_predictions = 0\n",
    "    correct_predictions_list = []\n",
    "    for i in range(0, len(predictions), 10):\n",
    "        for j in range(10):\n",
    "            if predictions[i + j].strip() == targets[current_target_index].strip():\n",
    "                correct_predictions += 1\n",
    "                correct_prediction_positons = {\n",
    "                    \"prediction\": i + j,\n",
    "                    \"target\": current_target_index,\n",
    "                }\n",
    "                correct_predictions_list.append(correct_prediction_positons)\n",
    "                break\n",
    "        current_target_index += 1\n",
    "\n",
    "    return correct_predictions_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 encoders perfect prediction percentage:  4.693140794223827 %\n",
      "2 encoders 10 beam perfect prediction  percentage:  20.938628158844764 %\n",
      "1 encoder perfect prediction  percentage:  1.5643802647412757 %\n",
      "1 encoder 10 beam perfect prediction  percentage:  10.348977135980746 %\n"
     ]
    }
   ],
   "source": [
    "def correct_predictions_percentage(predictions, targets):\n",
    "    assert len(predictions) == len(targets)\n",
    "    correct = 0\n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] == targets[i]:\n",
    "            correct += 1\n",
    "    return correct / len(targets) * 100\n",
    "\n",
    "print(\"2 encoders perfect prediction percentage: \", correct_predictions_percentage(two_encoders_one_beam_predictions, two_encoders_target), \"%\")\n",
    "print(\"2 encoders 10 beam perfect prediction  percentage: \", correct_predictions_percentage_10_beam(two_encoders_ten_beam_predictions, two_encoders_target), \"%\")\n",
    "\n",
    "print(\"1 encoder perfect prediction  percentage: \", correct_predictions_percentage(one_encoder_one_beam_predictions, one_encoder_target), \"%\")\n",
    "print(\"1 encoder 10 beam perfect prediction  percentage: \", correct_predictions_percentage_10_beam(one_encoder_ten_beam_predictions, one_encoder_target), \"%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perfect Prediction Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 encoders 1 beam correct predictions:  [90, 95, 134, 136, 140, 191, 238, 263, 278, 287, 296, 337, 351, 367, 380, 382, 398, 420, 435, 456, 484, 492, 525, 574, 606, 613, 649, 657, 675, 705, 713, 720, 729, 781, 791, 796, 797, 800, 821]\n",
      "2 encoders 10 beam correct predictions:  [{'prediction': 131, 'target': 13}, {'prediction': 191, 'target': 19}, {'prediction': 384, 'target': 38}, {'prediction': 391, 'target': 39}, {'prediction': 482, 'target': 48}, {'prediction': 741, 'target': 74}, {'prediction': 754, 'target': 75}, {'prediction': 891, 'target': 89}, {'prediction': 900, 'target': 90}, {'prediction': 930, 'target': 93}, {'prediction': 950, 'target': 95}, {'prediction': 1041, 'target': 104}, {'prediction': 1141, 'target': 114}, {'prediction': 1179, 'target': 117}, {'prediction': 1332, 'target': 133}, {'prediction': 1361, 'target': 136}, {'prediction': 1400, 'target': 140}, {'prediction': 1425, 'target': 142}, {'prediction': 1502, 'target': 150}, {'prediction': 1576, 'target': 157}, {'prediction': 1622, 'target': 162}, {'prediction': 1652, 'target': 165}, {'prediction': 1770, 'target': 177}, {'prediction': 1910, 'target': 191}, {'prediction': 1950, 'target': 195}, {'prediction': 1974, 'target': 197}, {'prediction': 1987, 'target': 198}, {'prediction': 2006, 'target': 200}, {'prediction': 2020, 'target': 202}, {'prediction': 2065, 'target': 206}, {'prediction': 2073, 'target': 207}, {'prediction': 2154, 'target': 215}, {'prediction': 2289, 'target': 228}, {'prediction': 2305, 'target': 230}, {'prediction': 2354, 'target': 235}, {'prediction': 2380, 'target': 238}, {'prediction': 2397, 'target': 239}, {'prediction': 2507, 'target': 250}, {'prediction': 2530, 'target': 253}, {'prediction': 2541, 'target': 254}, {'prediction': 2563, 'target': 256}, {'prediction': 2630, 'target': 263}, {'prediction': 2648, 'target': 264}, {'prediction': 2688, 'target': 268}, {'prediction': 2703, 'target': 270}, {'prediction': 2789, 'target': 278}, {'prediction': 2802, 'target': 280}, {'prediction': 2821, 'target': 282}, {'prediction': 2844, 'target': 284}, {'prediction': 2865, 'target': 286}, {'prediction': 2870, 'target': 287}, {'prediction': 2939, 'target': 293}, {'prediction': 2960, 'target': 296}, {'prediction': 3024, 'target': 302}, {'prediction': 3101, 'target': 310}, {'prediction': 3258, 'target': 325}, {'prediction': 3316, 'target': 331}, {'prediction': 3370, 'target': 337}, {'prediction': 3392, 'target': 339}, {'prediction': 3511, 'target': 351}, {'prediction': 3591, 'target': 359}, {'prediction': 3670, 'target': 367}, {'prediction': 3750, 'target': 375}, {'prediction': 3775, 'target': 377}, {'prediction': 3800, 'target': 380}, {'prediction': 3812, 'target': 381}, {'prediction': 3822, 'target': 382}, {'prediction': 3860, 'target': 386}, {'prediction': 3981, 'target': 398}, {'prediction': 4086, 'target': 408}, {'prediction': 4096, 'target': 409}, {'prediction': 4174, 'target': 417}, {'prediction': 4200, 'target': 420}, {'prediction': 4228, 'target': 422}, {'prediction': 4270, 'target': 427}, {'prediction': 4293, 'target': 429}, {'prediction': 4310, 'target': 431}, {'prediction': 4350, 'target': 435}, {'prediction': 4361, 'target': 436}, {'prediction': 4395, 'target': 439}, {'prediction': 4400, 'target': 440}, {'prediction': 4431, 'target': 443}, {'prediction': 4491, 'target': 449}, {'prediction': 4560, 'target': 456}, {'prediction': 4588, 'target': 458}, {'prediction': 4610, 'target': 461}, {'prediction': 4628, 'target': 462}, {'prediction': 4660, 'target': 466}, {'prediction': 4713, 'target': 471}, {'prediction': 4822, 'target': 482}, {'prediction': 4840, 'target': 484}, {'prediction': 4877, 'target': 487}, {'prediction': 4889, 'target': 488}, {'prediction': 4916, 'target': 491}, {'prediction': 4929, 'target': 492}, {'prediction': 4971, 'target': 497}, {'prediction': 4981, 'target': 498}, {'prediction': 5015, 'target': 501}, {'prediction': 5021, 'target': 502}, {'prediction': 5171, 'target': 517}, {'prediction': 5197, 'target': 519}, {'prediction': 5231, 'target': 523}, {'prediction': 5251, 'target': 525}, {'prediction': 5297, 'target': 529}, {'prediction': 5513, 'target': 551}, {'prediction': 5542, 'target': 554}, {'prediction': 5564, 'target': 556}, {'prediction': 5660, 'target': 566}, {'prediction': 5690, 'target': 569}, {'prediction': 5723, 'target': 572}, {'prediction': 5732, 'target': 573}, {'prediction': 5742, 'target': 574}, {'prediction': 5765, 'target': 576}, {'prediction': 5801, 'target': 580}, {'prediction': 6014, 'target': 601}, {'prediction': 6020, 'target': 602}, {'prediction': 6062, 'target': 606}, {'prediction': 6134, 'target': 613}, {'prediction': 6177, 'target': 617}, {'prediction': 6191, 'target': 619}, {'prediction': 6230, 'target': 623}, {'prediction': 6240, 'target': 624}, {'prediction': 6257, 'target': 625}, {'prediction': 6361, 'target': 636}, {'prediction': 6408, 'target': 640}, {'prediction': 6417, 'target': 641}, {'prediction': 6493, 'target': 649}, {'prediction': 6524, 'target': 652}, {'prediction': 6530, 'target': 653}, {'prediction': 6572, 'target': 657}, {'prediction': 6600, 'target': 660}, {'prediction': 6623, 'target': 662}, {'prediction': 6663, 'target': 666}, {'prediction': 6671, 'target': 667}, {'prediction': 6758, 'target': 675}, {'prediction': 6760, 'target': 676}, {'prediction': 6781, 'target': 678}, {'prediction': 6791, 'target': 679}, {'prediction': 6882, 'target': 688}, {'prediction': 6898, 'target': 689}, {'prediction': 6903, 'target': 690}, {'prediction': 6924, 'target': 692}, {'prediction': 7050, 'target': 705}, {'prediction': 7105, 'target': 710}, {'prediction': 7111, 'target': 711}, {'prediction': 7130, 'target': 713}, {'prediction': 7201, 'target': 720}, {'prediction': 7266, 'target': 726}, {'prediction': 7290, 'target': 729}, {'prediction': 7311, 'target': 731}, {'prediction': 7350, 'target': 735}, {'prediction': 7473, 'target': 747}, {'prediction': 7612, 'target': 761}, {'prediction': 7684, 'target': 768}, {'prediction': 7731, 'target': 773}, {'prediction': 7744, 'target': 774}, {'prediction': 7817, 'target': 781}, {'prediction': 7832, 'target': 783}, {'prediction': 7878, 'target': 787}, {'prediction': 7901, 'target': 790}, {'prediction': 7910, 'target': 791}, {'prediction': 7922, 'target': 792}, {'prediction': 7964, 'target': 796}, {'prediction': 7972, 'target': 797}, {'prediction': 8000, 'target': 800}, {'prediction': 8071, 'target': 807}, {'prediction': 8096, 'target': 809}, {'prediction': 8111, 'target': 811}, {'prediction': 8203, 'target': 820}, {'prediction': 8211, 'target': 821}, {'prediction': 8244, 'target': 824}, {'prediction': 8251, 'target': 825}, {'prediction': 8262, 'target': 826}, {'prediction': 8300, 'target': 830}]\n",
      "1 encoder correct predictions:  [91, 135, 145, 215, 359, 421, 553, 614, 618, 632, 715, 802, 823]\n",
      "1 encoder 10 beam correct predictions:  [{'prediction': 81, 'target': 8}, {'prediction': 323, 'target': 32}, {'prediction': 427, 'target': 42}, {'prediction': 506, 'target': 50}, {'prediction': 712, 'target': 71}, {'prediction': 782, 'target': 78}, {'prediction': 910, 'target': 91}, {'prediction': 971, 'target': 97}, {'prediction': 1081, 'target': 108}, {'prediction': 1350, 'target': 135}, {'prediction': 1396, 'target': 139}, {'prediction': 1430, 'target': 143}, {'prediction': 1450, 'target': 145}, {'prediction': 1525, 'target': 152}, {'prediction': 1552, 'target': 155}, {'prediction': 1593, 'target': 159}, {'prediction': 1641, 'target': 164}, {'prediction': 1758, 'target': 175}, {'prediction': 1843, 'target': 184}, {'prediction': 1897, 'target': 189}, {'prediction': 1933, 'target': 193}, {'prediction': 1941, 'target': 194}, {'prediction': 2104, 'target': 210}, {'prediction': 2150, 'target': 215}, {'prediction': 2174, 'target': 217}, {'prediction': 2316, 'target': 231}, {'prediction': 2637, 'target': 263}, {'prediction': 2665, 'target': 266}, {'prediction': 2841, 'target': 284}, {'prediction': 2960, 'target': 296}, {'prediction': 3014, 'target': 301}, {'prediction': 3160, 'target': 316}, {'prediction': 3171, 'target': 317}, {'prediction': 3203, 'target': 320}, {'prediction': 3220, 'target': 322}, {'prediction': 3402, 'target': 340}, {'prediction': 3513, 'target': 351}, {'prediction': 3594, 'target': 359}, {'prediction': 3801, 'target': 380}, {'prediction': 3846, 'target': 384}, {'prediction': 3951, 'target': 395}, {'prediction': 4012, 'target': 401}, {'prediction': 4190, 'target': 419}, {'prediction': 4210, 'target': 421}, {'prediction': 4281, 'target': 428}, {'prediction': 4382, 'target': 438}, {'prediction': 4403, 'target': 440}, {'prediction': 4511, 'target': 451}, {'prediction': 4714, 'target': 471}, {'prediction': 4733, 'target': 473}, {'prediction': 4811, 'target': 481}, {'prediction': 4913, 'target': 491}, {'prediction': 5096, 'target': 509}, {'prediction': 5164, 'target': 516}, {'prediction': 5220, 'target': 522}, {'prediction': 5530, 'target': 553}, {'prediction': 5540, 'target': 554}, {'prediction': 5790, 'target': 579}, {'prediction': 5930, 'target': 593}, {'prediction': 6008, 'target': 600}, {'prediction': 6091, 'target': 609}, {'prediction': 6140, 'target': 614}, {'prediction': 6180, 'target': 618}, {'prediction': 6320, 'target': 632}, {'prediction': 6462, 'target': 646}, {'prediction': 6582, 'target': 658}, {'prediction': 6690, 'target': 669}, {'prediction': 6792, 'target': 679}, {'prediction': 7028, 'target': 702}, {'prediction': 7054, 'target': 705}, {'prediction': 7111, 'target': 711}, {'prediction': 7151, 'target': 715}, {'prediction': 7207, 'target': 720}, {'prediction': 7440, 'target': 744}, {'prediction': 7705, 'target': 770}, {'prediction': 7771, 'target': 777}, {'prediction': 7870, 'target': 787}, {'prediction': 7911, 'target': 791}, {'prediction': 7981, 'target': 798}, {'prediction': 8021, 'target': 802}, {'prediction': 8090, 'target': 809}, {'prediction': 8104, 'target': 810}, {'prediction': 8210, 'target': 821}, {'prediction': 8231, 'target': 823}, {'prediction': 8284, 'target': 828}, {'prediction': 8297, 'target': 829}]\n"
     ]
    }
   ],
   "source": [
    "def get_correct_predictions(predictions, targets):\n",
    "    assert len(predictions) == len(targets)\n",
    "    correct = []\n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] == targets[i]:\n",
    "            correct.append(i)\n",
    "    return correct\n",
    "\n",
    "two_encoders_one_beam_correct_predictions = get_correct_predictions(two_encoders_one_beam_predictions, two_encoders_target)\n",
    "two_encoders_ten_beam_correct_predictions = get_correct_predictions_10_beam(two_encoders_ten_beam_predictions, two_encoders_target)\n",
    "\n",
    "one_encoder_one_beam_correct_predictions = get_correct_predictions(one_encoder_one_beam_predictions, one_encoder_target)\n",
    "one_encoder_ten_beam_correct_predictions = get_correct_predictions_10_beam(one_encoder_ten_beam_predictions, one_encoder_target)\n",
    "\n",
    "print(\"2 encoders 1 beam correct predictions: \", two_encoders_one_beam_correct_predictions)\n",
    "print(\"2 encoders 10 beam correct predictions: \", two_encoders_ten_beam_correct_predictions)\n",
    "\n",
    "print(\"1 encoder correct predictions: \", one_encoder_one_beam_correct_predictions)\n",
    "print(\"1 encoder 10 beam correct predictions: \", one_encoder_ten_beam_correct_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mapping(ms):\n",
    "    ms = ms.replace(\"\\n\", \"\")\n",
    "    map_str = dataset_with_mapping[dataset_with_mapping[\"ms\"] == ms][\"map\"].values[0]\n",
    "    mapping = eval(map_str)\n",
    "    return mapping\n",
    "\n",
    "def revert_abstracted_data(data, mapping):\n",
    "    for key, value in mapping.items():\n",
    "        data = data.replace(value, key)\n",
    "    return data\n",
    "\n",
    "def print_sample(ms, rnl, prediction, target, mapping):\n",
    "    print(\"MS Abstracted: \", ms)\n",
    "    print(\"MS: \", revert_abstracted_data(ms, mapping))\n",
    "\n",
    "    if rnl is not None:\n",
    "        print(\"RNL Abstracted: \", rnl)\n",
    "        print(\"RNL: \", revert_abstracted_data(rnl, mapping))\n",
    "\n",
    "    print(\"Prediction Abstracted: \", prediction)\n",
    "    print(\"Prediction: \", revert_abstracted_data(prediction, mapping))\n",
    "\n",
    "    print(\"Target Abstracted: \", target)\n",
    "    print(\"Target: \", revert_abstracted_data(target, mapping))\n",
    "\n",
    "def get_sample(index, ms, rnl, one_beam_predictions, target, ten_beam_predictions=None, prediction_index=None, target_index=None):\n",
    "    if ten_beam_predictions is not None:\n",
    "        mapping = get_mapping(ms[target_index])\n",
    "        prediction = ten_beam_predictions[prediction_index]\n",
    "        target_sample = target[target_index]\n",
    "        print_sample(ms[target_index], rnl[target_index] if rnl else None, prediction, target_sample, mapping)\n",
    "    else:\n",
    "        mapping = get_mapping(ms[index])\n",
    "        print_sample(ms[index], rnl[index] if rnl else None, one_beam_predictions[index], target[index], mapping)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 Beam Size Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 2 encoder 1 beam size: \n",
      "MS Abstracted:  public void VAR_1 ( VAR_2 VAR_1 ) { this . VAR_1 = VAR_1 ; } }\n",
      "\n",
      "MS:  public void analysisReportScreen ( AnalysisReportScreen analysisReportScreen ) { this . analysisReportScreen = analysisReportScreen ; } }\n",
      "\n",
      "RNL Abstracted:  Could use final VAR_2 VAR_1 please\n",
      "\n",
      "RNL:  Could use final AnalysisReportScreen analysisReportScreen please\n",
      "\n",
      "Prediction Abstracted:  public void VAR_1 ( final VAR_2 VAR_1 ) { this . VAR_1 = VAR_1 ; } }\n",
      "\n",
      "Prediction:  public void analysisReportScreen ( final AnalysisReportScreen analysisReportScreen ) { this . analysisReportScreen = analysisReportScreen ; } }\n",
      "\n",
      "Target Abstracted:  public void VAR_1 ( final VAR_2 VAR_1 ) { this . VAR_1 = VAR_1 ; } }\n",
      "\n",
      "Target:  public void analysisReportScreen ( final AnalysisReportScreen analysisReportScreen ) { this . analysisReportScreen = analysisReportScreen ; } }\n",
      "\n",
      "**************************************************\n",
      "Sample 1 encoder 1 beam size: \n",
      "MS Abstracted:  protected synchronized void METHOD_1 ( ) { }\n",
      "\n",
      "MS:  protected synchronized void preTrackingEventMethod ( ) { }\n",
      "\n",
      "Prediction Abstracted:  protected void METHOD_1 ( ) { }\n",
      "\n",
      "Prediction:  protected void preTrackingEventMethod ( ) { }\n",
      "\n",
      "Target Abstracted:  protected void METHOD_1 ( ) { }\n",
      "\n",
      "Target:  protected void preTrackingEventMethod ( ) { }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample 2 encoder 1 beam size: \")\n",
    "get_sample(two_encoders_one_beam_correct_predictions[0], two_encoders_ms, two_encoders_rnl, two_encoders_one_beam_predictions, two_encoders_target)\n",
    "print(\"*\" * 50)\n",
    "print(\"Sample 1 encoder 1 beam size: \")\n",
    "get_sample(one_encoder_one_beam_correct_predictions[0], one_encoder_ms, None, one_encoder_one_beam_predictions, one_encoder_target)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10 Beam Size Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 2 encoder with 10 beam: \n",
      "MS Abstracted:  public static TYPE_1 METHOD_1 ( String VAR_1 ) { try { return TYPE_1 . METHOD_2 ( VAR_1 ) ; } catch ( final TYPE_2 VAR_2 ) { TYPE_3 VAR_3 = TYPE_4 . METHOD_1 ( VAR_1 ) ; if ( null == VAR_3 ) return null ; try { return TYPE_1 . METHOD_3 ( VAR_3 ) ; } catch ( final TYPE_2 VAR_4 ) { return null ; } } }\n",
      "\n",
      "MS:  public static DateTimeZone getTimeZone ( String timezoneParam ) { try { return DateTimeZone . forID ( timezoneParam ) ; } catch ( final IllegalArgumentException e ) { TimeZone zone = ZoneInfo . getTimeZone ( timezoneParam ) ; if ( null == zone ) return null ; try { return DateTimeZone . forTimeZone ( zone ) ; } catch ( final IllegalArgumentException e1 ) { return null ; } } }\n",
      "\n",
      "RNL Abstracted:  Can write curly braces block instead 1 line\n",
      "\n",
      "RNL:  Can write curly braces block instead 1 line\n",
      "\n",
      "Prediction Abstracted:  public static TYPE_1 METHOD_1 ( String VAR_1 ) { try { return TYPE_1 . METHOD_2 ( VAR_1 ) ; } catch ( final TYPE_2 VAR_2 ) { TYPE_3 VAR_3 = TYPE_4 . METHOD_1 ( VAR_1 ) ; if ( null == VAR_3 ) { return null ; } try { return TYPE_1 . METHOD_3 ( VAR_3 ) ; } catch ( final TYPE_2 VAR_4 ) { return null ; } } }\n",
      "\n",
      "Prediction:  public static DateTimeZone getTimeZone ( String timezoneParam ) { try { return DateTimeZone . forID ( timezoneParam ) ; } catch ( final IllegalArgumentException e ) { TimeZone zone = ZoneInfo . getTimeZone ( timezoneParam ) ; if ( null == zone ) { return null ; } try { return DateTimeZone . forTimeZone ( zone ) ; } catch ( final IllegalArgumentException e1 ) { return null ; } } }\n",
      "\n",
      "Target Abstracted:  public static TYPE_1 METHOD_1 ( String VAR_1 ) { try { return TYPE_1 . METHOD_2 ( VAR_1 ) ; } catch ( final TYPE_2 VAR_2 ) { TYPE_3 VAR_3 = TYPE_4 . METHOD_1 ( VAR_1 ) ; if ( null == VAR_3 ) { return null ; } try { return TYPE_1 . METHOD_3 ( VAR_3 ) ; } catch ( final TYPE_2 VAR_4 ) { return null ; } } }\n",
      "\n",
      "Target:  public static DateTimeZone getTimeZone ( String timezoneParam ) { try { return DateTimeZone . forID ( timezoneParam ) ; } catch ( final IllegalArgumentException e ) { TimeZone zone = ZoneInfo . getTimeZone ( timezoneParam ) ; if ( null == zone ) { return null ; } try { return DateTimeZone . forTimeZone ( zone ) ; } catch ( final IllegalArgumentException e1 ) { return null ; } } }\n",
      "\n",
      "**************************************************\n",
      "Sample 1 encoder with 10 beam: \n",
      "MS Abstracted:  public static String METHOD_1 ( TYPE_1 file ) throws TYPE_2 { return TYPE_3 . METHOD_2 ( file . METHOD_3 ( ) ) . toLowerCase ( ) ; }\n",
      "\n",
      "MS:  public static String getFileExtension ( File file ) throws Exception { return FilenameUtils . getExtension ( file . getAbsolutePath ( ) ) . toLowerCase ( ) ; }\n",
      "\n",
      "Prediction Abstracted:  public static String METHOD_1 ( TYPE_1 file ) { return TYPE_3 . METHOD_2 ( file . METHOD_3 ( ) ) . toLowerCase ( ) ; }\n",
      "\n",
      "Prediction:  public static String getFileExtension ( File file ) { return FilenameUtils . getExtension ( file . getAbsolutePath ( ) ) . toLowerCase ( ) ; }\n",
      "\n",
      "Target Abstracted:  public static String METHOD_1 ( TYPE_1 file ) { return TYPE_3 . METHOD_2 ( file . METHOD_3 ( ) ) . toLowerCase ( ) ; }\n",
      "\n",
      "Target:  public static String getFileExtension ( File file ) { return FilenameUtils . getExtension ( file . getAbsolutePath ( ) ) . toLowerCase ( ) ; }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample 2 encoder with 10 beam: \")\n",
    "get_sample(None, two_encoders_ms, two_encoders_rnl, None, two_encoders_target, two_encoders_ten_beam_predictions, two_encoders_ten_beam_correct_predictions[0][\"prediction\"], two_encoders_ten_beam_correct_predictions[0][\"target\"])\n",
    "print(\"*\" * 50)\n",
    "print(\"Sample 1 encoder with 10 beam: \")\n",
    "get_sample(None, one_encoder_ms, None, None, one_encoder_target, one_encoder_ten_beam_predictions, one_encoder_ten_beam_correct_predictions[0][\"prediction\"], one_encoder_ten_beam_correct_predictions[0][\"target\"])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Graphs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-encoder model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Beam"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=\"545\" alt=\"image\" src=\"https://user-images.githubusercontent.com/46859098/236644947-06124430-fd71-42f5-a590-013978daf9dc.png\">\n",
    "\n",
    "<img width=\"535\" alt=\"image\" src=\"https://user-images.githubusercontent.com/46859098/236645065-2a1b1cfc-52fc-4381-9591-80d8f45d1a68.png\">\n",
    "\n",
    "<img width=\"549\" alt=\"image\" src=\"https://user-images.githubusercontent.com/46859098/236645089-2ba583a8-6aa7-46cd-8cd6-a11a05ee9f7b.png\">\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 Beam"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=\"469\" alt=\"image\" src=\"https://user-images.githubusercontent.com/46859098/236666450-f9af1965-f257-4b4a-8448-e662e75a38aa.png\">\n",
    "<img width=\"782\" alt=\"image\" src=\"https://user-images.githubusercontent.com/46859098/236666474-141b9ca1-5c8c-4ed2-828e-0e2281293120.png\">\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-encoders model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Beam"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=\"547\" alt=\"image\" src=\"https://user-images.githubusercontent.com/46859098/236645239-136b89a0-9812-4c55-a024-28537f7e69b5.png\">\n",
    "<img width=\"542\" alt=\"image\" src=\"https://user-images.githubusercontent.com/46859098/236645258-b9672f9b-fdc0-43e7-af5b-ea75d3a6782d.png\">\n",
    "<img width=\"537\" alt=\"image\" src=\"https://user-images.githubusercontent.com/46859098/236645268-f216ce2d-ccd9-481b-9929-fd64059dfbbf.png\">\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 Beam"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=\"423\" alt=\"image\" src=\"https://user-images.githubusercontent.com/46859098/236663474-f63967e2-38af-4a8b-b64c-34065e730b35.png\">\n",
    "\n",
    "<img width=\"792\" alt=\"image\" src=\"https://user-images.githubusercontent.com/46859098/236663493-c2f67c00-0f37-4b2d-90fb-b63b78744670.png\">\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
