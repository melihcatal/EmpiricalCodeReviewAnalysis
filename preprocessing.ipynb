{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d7d2be8f",
   "metadata": {},
   "source": [
    "ESE P6: An Empirical Study of GitHub code review tool \n",
    "by Eleonora Pura  and Melih Catal\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "63adb053",
   "metadata": {},
   "source": [
    "## Data Mining\n",
    "This step is skipped because the data is already ready and given by the tutor."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "541b171d",
   "metadata": {},
   "source": [
    "## Methods Extraction and Linking Reviewer Comment\n",
    "Parsing Java files using the Lizard Python library to extract the methods. We are only interested in the java files.\n",
    "Link each comment to the specific method (if any) it refers to. If a comment cannot be linked to any method, it is discarded. After having linked comments to methods for each review round, we are in the situation in which we have, for each review round, a set of triplets <ms,mr and {Rnl}> where ms and mr represent the same method before and after the review round, and Rnl is a set of comments ms received in this round."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00793b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lizard\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')  # download the stop words corpus\n",
    "from nltk.corpus import stopwords\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a378abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_function_body(source_code, start_line, end_line):\n",
    "    lines = source_code.split('\\n')[start_line-1: end_line+1]\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "# TODO: check if comment_start_line and comment_end line are the correct ones\n",
    "def comment_in_method_body(comment_start_line, comment_end_line, function_start_line, function_end_line):\n",
    "    comment_range = set(range(comment_start_line, comment_end_line+1))\n",
    "    function_range = set(range(function_start_line, function_end_line+1))\n",
    "    \n",
    "    if comment_range.issubset(function_range):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "# TODO: fix function, not working yet\n",
    "def remove_unchanged_functions(functions_while, functions_after):\n",
    "    if functions_while == [] or functions_after == []:\n",
    "        return functions_while, functions_after\n",
    "    \n",
    "    for index, (function_while, function_after) in enumerate(zip(functions_while, functions_after)):\n",
    "        if function_while == function_after:\n",
    "            del functions_while[index]\n",
    "            del functions_after[index]\n",
    "            \n",
    "    return functions_while, functions_after\n",
    "\n",
    "def is_reviewer_commenting(owner_id, user_id):\n",
    "    if owner_id != user_id:\n",
    "        return True\n",
    "    \n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f973d20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/gh_apache_!_accumulo.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a451d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all the function from a row of the df\n",
    "def extract_row_functions(row, file_content):\n",
    "    functions = []\n",
    "    # Taken from Melih's code:\n",
    "    # if the comment start line is na that means the comment is a single line comment so we use the end line number as the start line number\n",
    "    comment_start_line = row['original_start_line'] if not pd.isna(row['original_start_line']) else row['original_line']\n",
    "    comment_end_line = row['original_line']\n",
    "    # Check that the comment is given by a reviewer\n",
    "    if is_reviewer_commenting(row['owner_id'], row['user_id']):\n",
    "        # Check that both start and end line are not NaN floats\n",
    "        if (not pd.isna(comment_start_line)) and (not pd.isna(comment_end_line)):\n",
    "            # Convert all start and end line to int \n",
    "            comment_start_line = int(comment_start_line)\n",
    "            comment_end_line = int(comment_end_line)\n",
    "\n",
    "            \n",
    "            l = lizard.analyze_file.analyze_source_code(row['filename'], row[file_content])\n",
    "            l_functions = l.function_list\n",
    "\n",
    "            for function in l_functions:\n",
    "                function_start_line = int(function.start_line)\n",
    "                function_end_line = int(function.end_line)\n",
    "                \n",
    "                # Check that the comment is part of the body of the function\n",
    "                if comment_in_method_body(comment_start_line, comment_end_line, function_start_line, function_end_line):\n",
    "                    body = find_function_body(row[file_content], function_start_line, function_end_line)\n",
    "                    \n",
    "                    functions.append(\n",
    "                        {\"name\": function.name,\n",
    "                         \"long_name\": function.long_name,\n",
    "                         \"start_line\": int(function.start_line),\n",
    "                         \"end_line\": int(function.end_line),\n",
    "                         \"body\": body})\n",
    "    return functions\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0e675c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of the original df\n",
    "df_copy = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce684ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions_while = []\n",
    "functions_after = []\n",
    "for idx, row in df_copy.iterrows():\n",
    "    row_functions_while = extract_row_functions(row, 'file_content_while')\n",
    "    row_functions_after = extract_row_functions(row, 'file_content_after')\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    #Remove the functions that remained unchanged\n",
    "    row_functions_while, row_functions_after = remove_unchanged_functions(functions_while, functions_after)\n",
    "    \"\"\"\n",
    "    \n",
    "    functions_while.append(row_functions_while)\n",
    "    functions_after.append(row_functions_after)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea679fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 2 new columns to df: functions_while and functions_after\n",
    "df_copy['functions_while'] = functions_while\n",
    "df_copy['functions_after'] = functions_after\n",
    "\n",
    "# Set all empty list values as np.nan in order to use pandas dropna function\n",
    "df_copy.functions_while = df_copy.functions_while.apply(lambda y: np.nan if len(y)==0 else y)\n",
    "df_copy.functions_after = df_copy.functions_after.apply(lambda y: np.nan if len(y)==0 else y)\n",
    "\n",
    "# Delete all entries in which there is no functions while or after\n",
    "df_copy = df_copy.dropna(subset=['functions_while', 'functions_after']).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# If the functions while and after remains the same that means that no error was fixed: remove from df\n",
    "df_copy = df_copy[df_copy['functions_while'] != df_copy['functions_after']].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf225469",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11efc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the dataframe in a list of triplets: (function_while, comment, function_after)\n",
    "triplets = []\n",
    "\n",
    "for idx, row in df_copy.iterrows():\n",
    "    if len(row['functions_while']) == len(row['functions_after']):\n",
    "        for function_while, function_after in zip(row['functions_while'], row['functions_after']):\n",
    "            triplets.append((function_while['body'], row['message'], function_after['body']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a1c5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Function while:\\n{triplets[0][0]}\\n\")\n",
    "print(f\"Review comment:\\n{triplets[0][1]}\\n\")\n",
    "print(f\"Function after:\\n{triplets[0][2]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc364fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(triplets))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c21732a5",
   "metadata": {},
   "source": [
    "## Abstraction\n",
    "Use `src2abs` tool to abstract the methods. Triplets for which a parsing error occur during the abstraction process on the ms or on the mr methods are removed from the dataset. ms and mr, after the abstraction must be different. Idioms are not abstracted. During the abstraction code comments are removed. Using the pair abstraction mode, the same literals/identifiers in the two methods weill be abstracted using the same IDs. As output of the abstract process, the tool provides an abstraction map M linking the abstracted token to the raw token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d15abb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_java_file(content, filename):\n",
    "    path = f\"./abstraction/java_files/{filename}\"\n",
    "    with open(path, 'w') as f:\n",
    "        f.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19370a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_abstraction_file():\n",
    "    code_granularity = \"method\"\n",
    "    mode = \"pair\"\n",
    "    idioms_path = \"./src2abs/idioms.csv\"\n",
    "    src2abs_path = \"./src2abs/src2abs-0.1-jar-with-dependencies.jar\"\n",
    "    input_code_A_path = \"./abstraction/java_files/ms.java\"\n",
    "    input_code_B_path = \"./abstraction/java_files/mr.java\"\n",
    "    output_abstract_A_path = \"./abstraction/abstraction_files/ms_abs.java\"\n",
    "    output_abstract_B_path = \"./abstraction/abstraction_files/mr_abs.java\"\n",
    "    try :\n",
    "        # java -jar src2abs-0.1-jar-with-dependencies.jar pair <code_granularity> <input_code_A_path> <input_code_B_path> <output_abstract_A_path> <output_abstract_B_path> <idioms_path>\n",
    "        command = ['java', '-jar', src2abs_path, mode, code_granularity, input_code_A_path, input_code_B_path, output_abstract_A_path, output_abstract_B_path, idioms_path]\n",
    "        # execute the command and capture the output\n",
    "        process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        stdout, stderr = process.communicate()\n",
    "        if stderr:\n",
    "            print(\"Error creating abstraction data\")\n",
    "            print(stderr)\n",
    "        #else :\n",
    "            #print(\"Abstraction data created\")\n",
    "    except Exception as e:\n",
    "        print(\"Error creating abstraction data\")\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f870066",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_abstraction_file(filename):\n",
    "    path = f\"./abstraction/abstraction_files/{filename}\"\n",
    "    with open(path, 'r') as f:\n",
    "        return f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982b754d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read mapping file and create a dictionary with the mapping. key: concrete, value: abstract\n",
    "def read_abstraction_mapping_file(filename):\n",
    "    path = f\"./abstraction/abstraction_files/{filename}\"\n",
    "    with open(path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    is_abstract = False\n",
    "    keys = []\n",
    "    values = []\n",
    "    for line in lines:\n",
    "        words = line.strip().split(',')\n",
    "        if len(words) > 1 :\n",
    "            for word in words:\n",
    "                if word == '':\n",
    "                    continue\n",
    "                if is_abstract:\n",
    "                    values.append(word)\n",
    "                else:\n",
    "                    keys.append(word)\n",
    "            is_abstract = not is_abstract\n",
    "     # convert the lists to a dictionary\n",
    "    maps = dict(zip(keys, values))\n",
    "\n",
    "\n",
    "    return maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b0f637",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "template_triplets_data = {\n",
    "    \"ms\": \"\",\n",
    "    \"comment\": \"\",\n",
    "    \"mr\": \"\"\n",
    "    \"ms_abs\": \"\",\n",
    "    \"mr_abs\": \"\",\n",
    "    \"map\" : dict()\n",
    "}\n",
    "ms = methods while\n",
    "mr = methods after change\n",
    "rnl = review comment\n",
    "'''\n",
    "triplets_with_abstraction = []\n",
    "def create_abstraction_data(ms,mr,rnl):\n",
    "    template_triplets_data = {}\n",
    "    create_java_file(ms, \"ms.java\")\n",
    "    create_java_file(mr, \"mr.java\")\n",
    "    create_abstraction_file()\n",
    "    ms_abs = read_abstraction_file(\"ms_abs.java\")\n",
    "    mr_abs = read_abstraction_file(\"mr_abs.java\")\n",
    "    mapping = read_abstraction_mapping_file(\"ms_abs.java.map\")\n",
    "    \n",
    "    template_triplets_data[\"ms\"] = ms\n",
    "    template_triplets_data[\"comment\"] = rnl\n",
    "    template_triplets_data[\"mr\"] = mr\n",
    "    template_triplets_data[\"ms_abs\"] = ms_abs\n",
    "    template_triplets_data[\"mr_abs\"] = mr_abs\n",
    "    template_triplets_data[\"map\"] = mapping\n",
    "    triplets_with_abstraction.append(template_triplets_data)\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8c4ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for triplet in triplets:\n",
    "    create_abstraction_data(triplet[0], triplet[2], triplet[1])\n",
    "\n",
    "print(len(triplets_with_abstraction))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "16ddd69e",
   "metadata": {},
   "source": [
    "## Abstracting Reviewer Comments \n",
    "Abstract all code components mentioned in any comment using the abstraction map. Any camel casse identifier that is not matched in the abstraction map but that it is present in the comment, is replaced by the special token _CODE_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d77da60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_camel_case(s):\n",
    "    # example: \"camelCase\", \"camelcase\", \"camelCaseCase\", \"camelCaseC\"\n",
    "    # not example: \"camel\", \"camelCase_\"\n",
    "    pattern = r'^(?:[A-Z][a-z]*|[a-z]+)((?:[A-Z][a-z]*))+$'\n",
    "    return bool(re.match(pattern, s))\n",
    "\n",
    "def remove_stop_words(comment):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = comment.split()\n",
    "    filtered_comment = [w for w in words if not w in stop_words]\n",
    "    return \" \".join(filtered_comment)\n",
    "    \n",
    "def abstract_reviewer_comments(triplets_with_abstraction):\n",
    "    camel_case_abs = \"_CODE_\"\n",
    "    for triplet in triplets_with_abstraction:\n",
    "        comment = triplet[\"comment\"]\n",
    "        mapping = triplet[\"map\"]\n",
    "        comment_words = comment.split()\n",
    "        for word in comment_words:\n",
    "            # remove any special characters from the word\n",
    "            word = re.sub(r'[^\\w\\s]', '', word)\n",
    "            if word in mapping:               \n",
    "                comment = comment.replace(word, mapping[word])\n",
    "            elif is_camel_case(word):\n",
    "                comment = comment.replace(word, camel_case_abs)\n",
    "        comment = remove_stop_words(comment)\n",
    "        triplet[\"comment_abs\"] = comment\n",
    "\n",
    "    return triplets_with_abstraction\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aeedfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "triplets_with_abstraction = abstract_reviewer_comments(triplets_with_abstraction)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4150e5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(triplets_with_abstraction[0]['comment'])\n",
    "print(triplets_with_abstraction[0]['comment_abs'])\n",
    "print(triplets_with_abstraction[0]['map'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1cbde39c",
   "metadata": {},
   "source": [
    "## Filtering out Noisy Comments\n",
    "Using heuristics to filter out noisy comments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba47b36d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14de8adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_relevant(comment):\n",
    "    comment_size = len(comment.split())\n",
    "\n",
    "    is_relevant = True\n",
    "    # Useless comments, no content after removing stopwords\n",
    "    if len(comment) == 0:\n",
    "        is_relevant = False\n",
    "\n",
    "    # Useless comments, one word, no action required or unclear action\n",
    "    elif comment_size == 1:\n",
    "        if comment.__contains__('nice') or comment.__contains__('pleas') \\\n",
    "            or comment.__contains__('ditto') or comment.__contains__('thank') \\\n",
    "            or comment.__contains__('ditto2') or comment.__contains__('fine') \\\n",
    "            or comment.__contains__('agew') or comment.__contains__('hahaha') \\\n",
    "            or comment.__contains__('yeh') or comment.__contains__('lol'):\n",
    "            is_relevant = False\n",
    "\n",
    "    elif comment_size == 2:\n",
    "        if comment.__contains__('ack'):\n",
    "            is_relevant =False\n",
    "\n",
    "    # Request to change formatting, no impact on code\n",
    "    elif comment.__contains__('indent') and comment_size < 5:\n",
    "        is_relevant = False\n",
    "\n",
    "    # Likely a thank you message\n",
    "    elif (comment.__contains__('works for me') or comment.__contains__('sounds good') \\\n",
    "        or comment.__contains__('makes sense') or comment.__contains__('smile') \\\n",
    "        or comment.__contains__('approv')) and comment_size < 5:\n",
    "        is_relevant = False\n",
    "\n",
    "    # Request to add test code, no impact on the reviewed code\n",
    "    elif (comment.__contains__('test') and comment_size < 5) \\\n",
    "        or (comment.__contains__('add') and comment.__contains__('test')):\n",
    "        is_relevant = False\n",
    "\n",
    "    # Request for clarification\n",
    "    elif ((comment.__contains__('please explain') or comment.__contains__('explan') \\\n",
    "            or comment.__contains__('wat') or comment.__contains__('what')) and comment_size < 5) \\\n",
    "        or ((comment.__contains__('understand') or comment.__contains__('meant')) \\\n",
    "            and comment.__contains__('not sure')):\n",
    "        is_relevant = False\n",
    "\n",
    "    # Refers to previous comment or external resource with unclear action point\n",
    "    elif (comment.__contains__('same as') or comment.__contains__('same remark') \\\n",
    "            or comment.__contains__('said above') or comment.__contains__('do the same')) \\\n",
    "        and comment_size < 5:\n",
    "        is_relevant = False\n",
    "\n",
    "    # Refers to web pages\n",
    "    elif (comment.__contains__('like') or comment.__contains__('see')) \\\n",
    "        and comment.__contains__('http'):\n",
    "        is_relevant = False\n",
    "\n",
    "    # Request to add comment\n",
    "    elif comment.__contains__('document') or comment.__contains__('javadoc') \\\n",
    "            or comment.__contains__('comment'):\n",
    "        is_relevant =  False\n",
    "\n",
    "    # Feedback about reorganizing the PR\n",
    "    elif comment.__contains__('pr') and comment_size < 5:\n",
    "        is_relevant = False\n",
    "\n",
    "    # Comment contains a +1 to support previous comment.\n",
    "    # It may be accompanied by another word, like agree or a smile.\n",
    "    # This is the reason for < 3\n",
    "    elif comment.__contains__('+1') and comment_size < 3:\n",
    "        is_relevant = False\n",
    "\n",
    "    # The code is ok for now\n",
    "    elif comment.__contains__('for now') and comment_size < 5:\n",
    "        is_relevant = False\n",
    "\n",
    "    # Answers\n",
    "    elif (comment.__contains__('fixed') or comment.__contains__('thank') \\\n",
    "            or comment.__contains__('youre right')) and comment_size < 3:\n",
    "        is_relevant = False\n",
    "    \n",
    "    return is_relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f491687f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell is for testing the is_relevant function and calculating the percentage of irrelevant comments among all comments\n",
    "# TODO: remove this cell when done testing\n",
    "\n",
    "# run is_relevant on all comments and get number of irrelevant comments \n",
    "def get_irrelevant_comments(triplets_with_abstraction):\n",
    "    irrelevant_comments = 0\n",
    "    for triplet in triplets_with_abstraction:\n",
    "        comment_abs = triplet[\"comment_abs\"]\n",
    "        if not is_relevant(comment_abs):\n",
    "            irrelevant_comments += 1\n",
    "    return irrelevant_comments\n",
    "\n",
    "\n",
    "irrelevant_comments = get_irrelevant_comments(triplets_with_abstraction)\n",
    "print(irrelevant_comments)\n",
    "print(len(triplets_with_abstraction) - irrelevant_comments)\n",
    "# percentage of irrelevant comments, the paper says in their dataset it is around 11%\n",
    "print(irrelevant_comments / len(triplets_with_abstraction) * 100)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
