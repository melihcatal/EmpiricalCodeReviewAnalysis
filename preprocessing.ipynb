{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d7d2be8f",
   "metadata": {},
   "source": [
    "ESE P6: An Empirical Study of GitHub code review tool \n",
    "by Eleonora Pura  and Melih Catal\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "70611a51",
   "metadata": {},
   "source": [
    "The goal of the preprocessing steps is to building two datasets of triplets (<ms,rnl>->mr) and pairs (ms->mr) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "63adb053",
   "metadata": {},
   "source": [
    "## Data Mining\n",
    "This step is skipped because the data is already ready and given by the tutor."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "541b171d",
   "metadata": {},
   "source": [
    "## Methods Extraction and Linking Reviewer Comment\n",
    "Parsing Java files using the Lizard Python library to extract the methods. We are only interested in the java files.\n",
    "Link each comment to the specific method (if any) it refers to. If a comment cannot be linked to any method, it is discarded. After having linked comments to methods for each review round, we are in the situation in which we have, for each review round, a set of triplets <ms,mr and {Rnl}> where ms and mr represent the same method before and after the review round, and Rnl is a set of comments ms received in this round."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a00793b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/melih/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import lizard\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')  # download the stop words corpus\n",
    "from nltk.corpus import stopwords\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a378abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_function_body(source_code, start_line, end_line):\n",
    "    lines = source_code.split('\\n')[start_line-1: end_line+1]\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "def comment_in_method_body(comment_start_line, comment_end_line, function_start_line, function_end_line):\n",
    "    comment_range = set(range(comment_start_line, comment_end_line+1))\n",
    "    function_range = set(range(function_start_line, function_end_line+1))\n",
    "    \n",
    "    if comment_range.issubset(function_range):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "# TODO: fix function, not working yet\n",
    "def remove_unchanged_functions(functions_while, functions_after):\n",
    "    if functions_while == [] or functions_after == []:\n",
    "        return functions_while, functions_after\n",
    "    \n",
    "    for index, (function_while, function_after) in enumerate(zip(functions_while, functions_after)):\n",
    "        if function_while == function_after:\n",
    "            del functions_while[index]\n",
    "            del functions_after[index]\n",
    "            \n",
    "    return functions_while, functions_after\n",
    "\n",
    "def is_reviewer_commenting(owner_id, user_id):\n",
    "    if owner_id != user_id:\n",
    "        return True\n",
    "    \n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61a451d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all the function from a row of the df\n",
    "def extract_row_functions(row, file_content):\n",
    "    functions = []\n",
    "    # if the comment start line is na that means the comment is a single line comment so we use the end line number as the start line number\n",
    "    comment_start_line = row['original_start_line'] if not pd.isna(row['original_start_line']) else row['original_line']\n",
    "    comment_end_line = row['original_line']\n",
    "    # Check that the comment is given by a reviewer\n",
    "    if is_reviewer_commenting(row['owner_id'], row['user_id']):\n",
    "        # Check that both start and end line are not NaN floats\n",
    "        if (not pd.isna(comment_start_line)) and (not pd.isna(comment_end_line)):\n",
    "            # Convert all start and end line to int \n",
    "            comment_start_line = int(comment_start_line)\n",
    "            comment_end_line = int(comment_end_line)\n",
    "\n",
    "            # Extract all the functions from the file\n",
    "            l = lizard.analyze_file.analyze_source_code(row['filename'], row[file_content])\n",
    "            l_functions = l.function_list\n",
    "\n",
    "            # \n",
    "            for function in l_functions:\n",
    "                function_start_line = int(function.start_line)\n",
    "                function_end_line = int(function.end_line)\n",
    "                \n",
    "                # Check that the comment is part of the body of the function\n",
    "                if comment_in_method_body(comment_start_line, comment_end_line, function_start_line, function_end_line):\n",
    "                    body = find_function_body(row[file_content], function_start_line, function_end_line)\n",
    "                    \n",
    "                    functions.append(\n",
    "                        {\"name\": function.name,\n",
    "                         \"long_name\": function.long_name,\n",
    "                         \"start_line\": int(function.start_line),\n",
    "                         \"end_line\": int(function.end_line),\n",
    "                         \"body\": body})\n",
    "    return functions\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12190961",
   "metadata": {},
   "outputs": [],
   "source": [
    "def methods_extraction_linking_reviewer_comments(df):\n",
    "    # Make a copy of the original df\n",
    "    df_copy = df.copy()\n",
    "    functions_while = []\n",
    "    functions_after = []\n",
    "    for idx, row in df_copy.iterrows():\n",
    "        row_functions_while = extract_row_functions(row, 'file_content_while')\n",
    "        row_functions_after = extract_row_functions(row, 'file_content_after')\n",
    "        \n",
    "        functions_while.append(row_functions_while)\n",
    "        functions_after.append(row_functions_after)\n",
    "    # Add 2 new columns to df: functions_while and functions_after\n",
    "    df_copy['functions_while'] = functions_while\n",
    "    df_copy['functions_after'] = functions_after\n",
    "\n",
    "    # Set all empty list values as np.nan in order to use pandas dropna function\n",
    "    df_copy.functions_while = df_copy.functions_while.apply(lambda y: np.nan if len(y)==0 else y)\n",
    "    df_copy.functions_after = df_copy.functions_after.apply(lambda y: np.nan if len(y)==0 else y)\n",
    "\n",
    "    # Delete all entries in which there is no functions while or after\n",
    "    df_copy = df_copy.dropna(subset=['functions_while', 'functions_after']).reset_index(drop=True)\n",
    "\n",
    "\n",
    "    # If the functions while and after remains the same that means that no error was fixed: remove from df\n",
    "    df_copy = df_copy[df_copy['functions_while'] != df_copy['functions_after']].reset_index(drop=True)\n",
    "\n",
    "    # Turn the dataframe in a list of triplets: (function_while, comment, function_after)\n",
    "    triplets = []\n",
    "\n",
    "    for idx, row in df_copy.iterrows():\n",
    "        if len(row['functions_while']) == len(row['functions_after']):\n",
    "            for function_while, function_after in zip(row['functions_while'], row['functions_after']):\n",
    "                triplets.append((function_while['body'], row['message'], function_after['body']))\n",
    "    \n",
    "    return triplets\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c21732a5",
   "metadata": {},
   "source": [
    "## Abstraction\n",
    "Use `src2abs` tool to abstract the methods. Triplets for which a parsing error occur during the abstraction process on the ms or on the mr methods are removed from the dataset. ms and mr, after the abstraction must be different. Idioms are not abstracted. During the abstraction code comments are removed. Using the pair abstraction mode, the same literals/identifiers in the two methods weill be abstracted using the same IDs. As output of the abstract process, the tool provides an abstraction map M linking the abstracted token to the raw token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d15abb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_java_file(content, filename):\n",
    "    path = f\"./abstraction/java_files/{filename}\"\n",
    "    with open(path, 'w') as f:\n",
    "        f.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "19370a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_abstraction_file():\n",
    "    code_granularity = \"method\"\n",
    "    mode = \"pair\"\n",
    "    idioms_path = \"./src2abs/idioms.csv\"\n",
    "    src2abs_path = \"./src2abs/src2abs-0.1-jar-with-dependencies.jar\"\n",
    "    input_code_A_path = \"./abstraction/java_files/ms.java\"\n",
    "    input_code_B_path = \"./abstraction/java_files/mr.java\"\n",
    "    output_abstract_A_path = \"./abstraction/abstraction_files/ms_abs.java\"\n",
    "    output_abstract_B_path = \"./abstraction/abstraction_files/mr_abs.java\"\n",
    "    try :\n",
    "        # java -jar src2abs-0.1-jar-with-dependencies.jar pair <code_granularity> <input_code_A_path> <input_code_B_path> <output_abstract_A_path> <output_abstract_B_path> <idioms_path>\n",
    "        command = ['java', '-jar', src2abs_path, mode, code_granularity, input_code_A_path, input_code_B_path, output_abstract_A_path, output_abstract_B_path, idioms_path]\n",
    "        # execute the command and capture the output\n",
    "        process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        stdout, stderr = process.communicate()\n",
    "        if stderr:\n",
    "            #print(\"Error creating abstraction data\")\n",
    "            #print(stderr)\n",
    "            pass\n",
    "        #else :\n",
    "            #print(\"Abstraction data created\")\n",
    "    except Exception as e:\n",
    "        pass\n",
    "        #print(\"Error creating abstraction data\")\n",
    "        #print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6f870066",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_abstraction_file(filename):\n",
    "    path = f\"./abstraction/abstraction_files/{filename}\"\n",
    "    with open(path, 'r') as f:\n",
    "        return f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "982b754d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read mapping file and create a dictionary with the mapping. key: concrete, value: abstract\n",
    "def read_abstraction_mapping_file(filename):\n",
    "    path = f\"./abstraction/abstraction_files/{filename}\"\n",
    "    with open(path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    is_abstract = False\n",
    "    keys = []\n",
    "    values = []\n",
    "    for line in lines:\n",
    "        words = line.strip().split(',')\n",
    "        if len(words) > 1 :\n",
    "            for word in words:\n",
    "                if word == '':\n",
    "                    continue\n",
    "                if is_abstract:\n",
    "                    values.append(word)\n",
    "                else:\n",
    "                    keys.append(word)\n",
    "            is_abstract = not is_abstract\n",
    "     # convert the lists to a dictionary\n",
    "    maps = dict(zip(keys, values))\n",
    "\n",
    "\n",
    "    return maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "26687581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def abstraction_filter_methods(ms,mr):\n",
    "    # ms and mr should be different \n",
    "    if ms == mr:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "        \n",
    "def clean_rnl(rnl):\n",
    "    # remove links\n",
    "    rnl = re.sub(r'http\\S+', '', rnl)\n",
    "    # superfluous punctuation\n",
    "    rnl = re.sub(r'[^\\w\\s]', '', rnl)\n",
    "    return rnl\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a4b0f637",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "template_triplets_data = {\n",
    "    \"ms\": \"\",\n",
    "    \"comment\": \"\",\n",
    "    \"mr\": \"\"\n",
    "    \"ms_abs\": \"\",\n",
    "    \"mr_abs\": \"\",\n",
    "    \"map\" : dict()\n",
    "}\n",
    "ms = methods while\n",
    "mr = methods after change\n",
    "rnl = review comment\n",
    "'''\n",
    "def create_abstraction_data(ms,mr,rnl):\n",
    "    template_triplets_data = {}\n",
    "    create_java_file(ms, \"ms.java\")\n",
    "    create_java_file(mr, \"mr.java\")\n",
    "    create_abstraction_file()\n",
    "    ms_abs = read_abstraction_file(\"ms_abs.java\")\n",
    "    mr_abs = read_abstraction_file(\"mr_abs.java\")\n",
    "    mapping = read_abstraction_mapping_file(\"ms_abs.java.map\")\n",
    "    rnl = clean_rnl(rnl)\n",
    "    \n",
    "    template_triplets_data[\"ms\"] = ms\n",
    "    template_triplets_data[\"comment\"] = rnl \n",
    "    template_triplets_data[\"mr\"] = mr\n",
    "    template_triplets_data[\"ms_abs\"] = ms_abs\n",
    "    template_triplets_data[\"mr_abs\"] = mr_abs\n",
    "    template_triplets_data[\"map\"] = mapping\n",
    "    if abstraction_filter_methods(ms_abs, mr_abs):\n",
    "        #triplets_with_abstraction.append(template_triplets_data)\n",
    "        return template_triplets_data\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f8c4ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def methods_abstraction(triplets):\n",
    "    triplets_with_abstraction = []\n",
    "    for triplet in triplets:\n",
    "        abstracted_method = create_abstraction_data(triplet[0], triplet[2], triplet[1])\n",
    "        if abstracted_method:\n",
    "            triplets_with_abstraction.append(abstracted_method)\n",
    "    return triplets_with_abstraction\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "16ddd69e",
   "metadata": {},
   "source": [
    "## Abstracting Reviewer Comments \n",
    "Abstract all code components mentioned in any comment using the abstraction map. Any camel casse identifier that is not matched in the abstraction map but that it is present in the comment, is replaced by the special token _CODE_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1d77da60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_camel_case(s):\n",
    "    # example: \"camelCase\", \"camelcase\", \"camelCaseCase\", \"camelCaseC\"\n",
    "    # not example: \"camel\", \"camelCase_\"\n",
    "    pattern = r'^(?:[A-Z][a-z]*|[a-z]+)((?:[A-Z][a-z]*))+$'\n",
    "    return bool(re.match(pattern, s))\n",
    "\n",
    "def remove_stop_words(comment):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = comment.split()\n",
    "    filtered_comment = [w for w in words if not w in stop_words]\n",
    "    return \" \".join(filtered_comment)\n",
    "\n",
    "\n",
    "def abstraction_filter_rnl(rnl):\n",
    "    if len(rnl.split()) > 100:\n",
    "        return False\n",
    "    else :\n",
    "        return True\n",
    "\n",
    "def abstract_reviewer_comments(triplets_with_abstraction):\n",
    "    camel_case_abs = \"_CODE_\"\n",
    "    for triplet in triplets_with_abstraction:\n",
    "        comment = triplet[\"comment\"]\n",
    "        mapping = triplet[\"map\"]\n",
    "        comment_words = comment.split()\n",
    "        for word in comment_words:\n",
    "            # remove any special characters from the word\n",
    "            word = re.sub(r'[^\\w\\s]', '', word)\n",
    "            if word in mapping:               \n",
    "                comment = comment.replace(word, mapping[word])\n",
    "            elif is_camel_case(word):\n",
    "                comment = comment.replace(word, camel_case_abs)\n",
    "        comment = remove_stop_words(comment)\n",
    "\n",
    "        if abstraction_filter_rnl(comment):\n",
    "            triplet[\"comment_abs\"] = comment\n",
    "        else :\n",
    "            # delete the triplet\n",
    "            triplets_with_abstraction.remove(triplet)\n",
    "\n",
    "    return triplets_with_abstraction\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1cbde39c",
   "metadata": {},
   "source": [
    "## Filtering out Noisy Comments\n",
    "Using heuristics to filter out noisy comments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba47b36d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "14de8adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_relevant(comment):\n",
    "    comment_size = len(comment.split())\n",
    "\n",
    "    is_relevant = True\n",
    "    # Useless comments, no content after removing stopwords\n",
    "    if len(comment) == 0:\n",
    "        is_relevant = False\n",
    "\n",
    "    # Useless comments, one word, no action required or unclear action\n",
    "    elif comment_size == 1:\n",
    "        if comment.__contains__('nice') or comment.__contains__('pleas') \\\n",
    "            or comment.__contains__('ditto') or comment.__contains__('thank') \\\n",
    "            or comment.__contains__('ditto2') or comment.__contains__('fine') \\\n",
    "            or comment.__contains__('agew') or comment.__contains__('hahaha') \\\n",
    "            or comment.__contains__('yeh') or comment.__contains__('lol'):\n",
    "            is_relevant = False\n",
    "\n",
    "    elif comment_size == 2:\n",
    "        if comment.__contains__('ack'):\n",
    "            is_relevant =False\n",
    "\n",
    "    # Request to change formatting, no impact on code\n",
    "    elif comment.__contains__('indent') and comment_size < 5:\n",
    "        is_relevant = False\n",
    "\n",
    "    # Likely a thank you message\n",
    "    elif (comment.__contains__('works for me') or comment.__contains__('sounds good') \\\n",
    "        or comment.__contains__('makes sense') or comment.__contains__('smile') \\\n",
    "        or comment.__contains__('approv')) and comment_size < 5:\n",
    "        is_relevant = False\n",
    "\n",
    "    # Request to add test code, no impact on the reviewed code\n",
    "    elif (comment.__contains__('test') and comment_size < 5) \\\n",
    "        or (comment.__contains__('add') and comment.__contains__('test')):\n",
    "        is_relevant = False\n",
    "\n",
    "    # Request for clarification\n",
    "    elif ((comment.__contains__('please explain') or comment.__contains__('explan') \\\n",
    "            or comment.__contains__('wat') or comment.__contains__('what')) and comment_size < 5) \\\n",
    "        or ((comment.__contains__('understand') or comment.__contains__('meant')) \\\n",
    "            and comment.__contains__('not sure')):\n",
    "        is_relevant = False\n",
    "\n",
    "    # Refers to previous comment or external resource with unclear action point\n",
    "    elif (comment.__contains__('same as') or comment.__contains__('same remark') \\\n",
    "            or comment.__contains__('said above') or comment.__contains__('do the same')) \\\n",
    "        and comment_size < 5:\n",
    "        is_relevant = False\n",
    "\n",
    "    # Refers to web pages\n",
    "    elif (comment.__contains__('like') or comment.__contains__('see')) \\\n",
    "        and comment.__contains__('http'):\n",
    "        is_relevant = False\n",
    "\n",
    "    # Request to add comment\n",
    "    elif comment.__contains__('document') or comment.__contains__('javadoc') \\\n",
    "            or comment.__contains__('comment'):\n",
    "        is_relevant =  False\n",
    "\n",
    "    # Feedback about reorganizing the PR\n",
    "    elif comment.__contains__('pr') and comment_size < 5:\n",
    "        is_relevant = False\n",
    "\n",
    "    # Comment contains a +1 to support previous comment.\n",
    "    # It may be accompanied by another word, like agree or a smile.\n",
    "    # This is the reason for < 3\n",
    "    elif comment.__contains__('+1') and comment_size < 3:\n",
    "        is_relevant = False\n",
    "\n",
    "    # The code is ok for now\n",
    "    elif comment.__contains__('for now') and comment_size < 5:\n",
    "        is_relevant = False\n",
    "\n",
    "    # Answers\n",
    "    elif (comment.__contains__('fixed') or comment.__contains__('thank') \\\n",
    "            or comment.__contains__('youre right')) and comment_size < 3:\n",
    "        is_relevant = False\n",
    "    \n",
    "    return is_relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f491687f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell is for testing the is_relevant function and calculating the percentage of irrelevant comments among all comments\n",
    "# TODO: remove this cell when done testing\n",
    "\n",
    "# run is_relevant on all comments and get number of irrelevant comments \n",
    "def get_irrelevant_comments(triplets_with_abstraction):\n",
    "    irrelevant_comments = 0\n",
    "    for triplet in triplets_with_abstraction:\n",
    "        # check if the key exists\n",
    "        if \"comment_abs\" not in triplet:\n",
    "            continue\n",
    "        comment_abs = triplet[\"comment_abs\"]\n",
    "        if not is_relevant(comment_abs):\n",
    "            irrelevant_comments += 1\n",
    "    return irrelevant_comments\n",
    "\n",
    "\n",
    "#irrelevant_comments = get_irrelevant_comments(triplets_with_abstraction)\n",
    "#print(irrelevant_comments)\n",
    "#print(len(triplets_with_abstraction) - irrelevant_comments)\n",
    "# percentage of irrelevant comments, the paper says in their dataset it is around 11%\n",
    "#print(irrelevant_comments / len(triplets_with_abstraction) * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5c12740d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove irrelevant comments\n",
    "def remove_irrelevant_comments(triplets_with_abstraction):\n",
    "    for triplet in triplets_with_abstraction:\n",
    "        # check if the key exists\n",
    "        if \"comment_abs\" not in triplet:\n",
    "            continue\n",
    "        comment_abs = triplet[\"comment_abs\"]\n",
    "        if not is_relevant(comment_abs):\n",
    "            triplets_with_abstraction.remove(triplet)\n",
    "    return triplets_with_abstraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "390518e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create <ms,mr,rnl> triple from the triplets_with_abstraction\n",
    "def create_ms_mr_rnl_triple(triplets_with_abstraction):\n",
    "    ms_mr_rnl_triplets = []\n",
    "    for triplet in triplets_with_abstraction:\n",
    "        try: \n",
    "            ms_mr_rnl_triplets.append({\n",
    "                \"ms\": triplet[\"ms_abs\"],\n",
    "                \"mr\": triplet[\"mr_abs\"],\n",
    "                \"rnl\": triplet[\"comment_abs\"]\n",
    "            })\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    return ms_mr_rnl_triplets\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cd823f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(path):\n",
    "    df = pd.read_csv(path)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "75484046",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    #path = './data/gh_apache_!_accumulo.csv'\n",
    "    folder = \"data\"\n",
    "    # number of files in the folder\n",
    "    num_files = len(os.listdir(folder))\n",
    "    # current file number\n",
    "    file_num = 1\n",
    "    ms_mr_rnl_triplets = []\n",
    "    # for each file in the folder run the process\n",
    "    for filename in os.listdir(folder):\n",
    "        print(\"*******************\")\n",
    "        print (\"Processing file \" + str(file_num) + \" out of \" + str(num_files))\n",
    "        path = os.path.join(folder, filename)\n",
    "        df = read_csv(path)\n",
    "        triplets = methods_extraction_linking_reviewer_comments(df)\n",
    "        triplets_with_abstracted_methods =  methods_abstraction(triplets)\n",
    "        triplets_with_abstraction = abstract_reviewer_comments(triplets_with_abstracted_methods)\n",
    "        # remove irrelevant comments\n",
    "        triplets_with_abstraction = remove_irrelevant_comments(triplets_with_abstraction)\n",
    "\n",
    "        # create <ms,mr,rnl> triple from the triplets_with_abstraction\n",
    "        current_ms_mr_rnl_triplet = create_ms_mr_rnl_triple(triplets_with_abstraction)\n",
    "        ms_mr_rnl_triplets.extend(current_ms_mr_rnl_triplet)\n",
    "        print(\"Finished processing file \" + str(file_num) + \" out of \" + str(num_files))\n",
    "        print(\"*******************\")\n",
    "        file_num += 1\n",
    "        \n",
    "    return ms_mr_rnl_triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e79e91c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing file 1 out of 1764\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/melih/Desktop/Dersler/ESE/code/data-wrangling/preprocessing.ipynb Cell 27\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/melih/Desktop/Dersler/ESE/code/data-wrangling/preprocessing.ipynb#X60sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m final_triple \u001b[39m=\u001b[39m main()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/melih/Desktop/Dersler/ESE/code/data-wrangling/preprocessing.ipynb#X60sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(final_triple))\n",
      "\u001b[1;32m/Users/melih/Desktop/Dersler/ESE/code/data-wrangling/preprocessing.ipynb Cell 27\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/melih/Desktop/Dersler/ESE/code/data-wrangling/preprocessing.ipynb#X60sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m df \u001b[39m=\u001b[39m read_csv(path)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/melih/Desktop/Dersler/ESE/code/data-wrangling/preprocessing.ipynb#X60sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m triplets \u001b[39m=\u001b[39m methods_extraction_linking_reviewer_comments(df)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/melih/Desktop/Dersler/ESE/code/data-wrangling/preprocessing.ipynb#X60sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m triplets_with_abstracted_methods \u001b[39m=\u001b[39m  methods_abstraction(triplets)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/melih/Desktop/Dersler/ESE/code/data-wrangling/preprocessing.ipynb#X60sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m triplets_with_abstraction \u001b[39m=\u001b[39m abstract_reviewer_comments(triplets_with_abstracted_methods)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/melih/Desktop/Dersler/ESE/code/data-wrangling/preprocessing.ipynb#X60sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# remove irrelevant comments\u001b[39;00m\n",
      "\u001b[1;32m/Users/melih/Desktop/Dersler/ESE/code/data-wrangling/preprocessing.ipynb Cell 27\u001b[0m in \u001b[0;36mmethods_abstraction\u001b[0;34m(triplets)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/melih/Desktop/Dersler/ESE/code/data-wrangling/preprocessing.ipynb#X60sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m triplets_with_abstraction \u001b[39m=\u001b[39m []\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/melih/Desktop/Dersler/ESE/code/data-wrangling/preprocessing.ipynb#X60sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m triplet \u001b[39min\u001b[39;00m triplets:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/melih/Desktop/Dersler/ESE/code/data-wrangling/preprocessing.ipynb#X60sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     abstracted_method \u001b[39m=\u001b[39m create_abstraction_data(triplet[\u001b[39m0\u001b[39;49m], triplet[\u001b[39m2\u001b[39;49m], triplet[\u001b[39m1\u001b[39;49m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/melih/Desktop/Dersler/ESE/code/data-wrangling/preprocessing.ipynb#X60sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mif\u001b[39;00m abstracted_method:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/melih/Desktop/Dersler/ESE/code/data-wrangling/preprocessing.ipynb#X60sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         triplets_with_abstraction\u001b[39m.\u001b[39mappend(abstracted_method)\n",
      "\u001b[1;32m/Users/melih/Desktop/Dersler/ESE/code/data-wrangling/preprocessing.ipynb Cell 27\u001b[0m in \u001b[0;36mcreate_abstraction_data\u001b[0;34m(ms, mr, rnl)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/melih/Desktop/Dersler/ESE/code/data-wrangling/preprocessing.ipynb#X60sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m create_java_file(ms, \u001b[39m\"\u001b[39m\u001b[39mms.java\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/melih/Desktop/Dersler/ESE/code/data-wrangling/preprocessing.ipynb#X60sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m create_java_file(mr, \u001b[39m\"\u001b[39m\u001b[39mmr.java\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/melih/Desktop/Dersler/ESE/code/data-wrangling/preprocessing.ipynb#X60sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m create_abstraction_file()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/melih/Desktop/Dersler/ESE/code/data-wrangling/preprocessing.ipynb#X60sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m ms_abs \u001b[39m=\u001b[39m read_abstraction_file(\u001b[39m\"\u001b[39m\u001b[39mms_abs.java\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/melih/Desktop/Dersler/ESE/code/data-wrangling/preprocessing.ipynb#X60sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m mr_abs \u001b[39m=\u001b[39m read_abstraction_file(\u001b[39m\"\u001b[39m\u001b[39mmr_abs.java\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m/Users/melih/Desktop/Dersler/ESE/code/data-wrangling/preprocessing.ipynb Cell 27\u001b[0m in \u001b[0;36mcreate_abstraction_file\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/melih/Desktop/Dersler/ESE/code/data-wrangling/preprocessing.ipynb#X60sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m command \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mjava\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m-jar\u001b[39m\u001b[39m'\u001b[39m, src2abs_path, mode, code_granularity, input_code_A_path, input_code_B_path, output_abstract_A_path, output_abstract_B_path, idioms_path]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/melih/Desktop/Dersler/ESE/code/data-wrangling/preprocessing.ipynb#X60sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# execute the command and capture the output\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/melih/Desktop/Dersler/ESE/code/data-wrangling/preprocessing.ipynb#X60sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m process \u001b[39m=\u001b[39m subprocess\u001b[39m.\u001b[39;49mPopen(command, stdout\u001b[39m=\u001b[39;49msubprocess\u001b[39m.\u001b[39;49mPIPE, stderr\u001b[39m=\u001b[39;49msubprocess\u001b[39m.\u001b[39;49mPIPE)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/melih/Desktop/Dersler/ESE/code/data-wrangling/preprocessing.ipynb#X60sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m stdout, stderr \u001b[39m=\u001b[39m process\u001b[39m.\u001b[39mcommunicate()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/melih/Desktop/Dersler/ESE/code/data-wrangling/preprocessing.ipynb#X60sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mif\u001b[39;00m stderr:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/melih/Desktop/Dersler/ESE/code/data-wrangling/preprocessing.ipynb#X60sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39m#print(\"Error creating abstraction data\")\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/melih/Desktop/Dersler/ESE/code/data-wrangling/preprocessing.ipynb#X60sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39m#print(stderr)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/subprocess.py:951\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask)\u001b[0m\n\u001b[1;32m    947\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtext_mode:\n\u001b[1;32m    948\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mTextIOWrapper(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr,\n\u001b[1;32m    949\u001b[0m                     encoding\u001b[39m=\u001b[39mencoding, errors\u001b[39m=\u001b[39merrors)\n\u001b[0;32m--> 951\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_child(args, executable, preexec_fn, close_fds,\n\u001b[1;32m    952\u001b[0m                         pass_fds, cwd, env,\n\u001b[1;32m    953\u001b[0m                         startupinfo, creationflags, shell,\n\u001b[1;32m    954\u001b[0m                         p2cread, p2cwrite,\n\u001b[1;32m    955\u001b[0m                         c2pread, c2pwrite,\n\u001b[1;32m    956\u001b[0m                         errread, errwrite,\n\u001b[1;32m    957\u001b[0m                         restore_signals,\n\u001b[1;32m    958\u001b[0m                         gid, gids, uid, umask,\n\u001b[1;32m    959\u001b[0m                         start_new_session)\n\u001b[1;32m    960\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m    961\u001b[0m     \u001b[39m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[1;32m    962\u001b[0m     \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m \u001b[39mfilter\u001b[39m(\u001b[39mNone\u001b[39;00m, (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdin, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr)):\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/subprocess.py:1777\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session)\u001b[0m\n\u001b[1;32m   1775\u001b[0m errpipe_data \u001b[39m=\u001b[39m \u001b[39mbytearray\u001b[39m()\n\u001b[1;32m   1776\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m-> 1777\u001b[0m     part \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49mread(errpipe_read, \u001b[39m50000\u001b[39;49m)\n\u001b[1;32m   1778\u001b[0m     errpipe_data \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m part\n\u001b[1;32m   1779\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m part \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(errpipe_data) \u001b[39m>\u001b[39m \u001b[39m50000\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "final_triple = main()\n",
    "print(len(final_triple))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
